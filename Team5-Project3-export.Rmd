---
title: "Team 5 - Project 3"
author: "Ariba Mandavia, Jose Fuentes, Marco Castro, Steven Gonzalez"
date: "2024-10-14"
output: html_document
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(dplyr)
library(dbplyr)
library(tidyr)
library(tibble)
library(rvest)
library(rlist)
library(readr)
library(XML)
library(xml2)
library(jsonlite)
library(arrow)
library(stringr)
library(digest)
library(duckdb)
```

## Reading original dataset

```{r init-db-connection}

con <- dbConnect(duckdb::duckdb())

# make an in-memory db and store the connection in a variable

duckdb_register(con, "jobs", read_parquet('datasets/jobs.parquet'))
duckdb_register(con, "skills", read_parquet('datasets/skills_delimned.parquet'))
duckdb_register(con, "job_skills", read_parquet('datasets/job_skills_delimned.parquet'))
duckdb_register(con, "companies",  read_parquet('datasets/companies.parquet'))

# read as df
jobs_df <- tbl(con, "jobs")
skills_df <- tbl(con, "skills")
job_skills_df <- tbl(con, "job_skills")
companies_df <- tbl(con, "companies")

head(jobs_df)

# Joined dataframe
full_df <- dbGetQuery(con,"WITH skills_by_id AS (
                    SELECT job_id,
                      STRING_AGG (skill_name, ',' ) AS skills
                    FROM job_skills AS x
                    LEFT JOIN skills AS s 
                      ON s.skill_id = x.skill_id 
                    GROUP BY job_id
                  )

                  SELECT j.*, c.company, s.skills
                  FROM jobs AS j
                  LEFT JOIN skills_by_id AS s
                      ON s.job_id = j.job_id 
                  LEFT JOIN companies AS c
                    ON c.company_id = j.company_id
            ")

glimpse(full_df)

```

**Data Tidying**



```{r}

# 1. Standardize Column Names
full_df <- full_df %>%
  rename_all(~str_to_lower(.)) %>%    # Convert all column names to lowercase
  rename_all(~str_replace_all(., " ", "_")) # Replace spaces with underscores

# 2. Remove Duplicates
full_df <- full_df %>%
  distinct()  # Keep only unique rows

# 3. Handle Missing Values
# Replace NA values with 'Unknown' in character columns
full_df <- full_df %>%
  mutate(across(where(is.character), ~replace_na(., "Unknown")))

# Display the cleaned data frame
head(full_df)

```


```{r}

# Assuming 'full_df' contains job postings and skill information

# 1. Separate the skills column back into individual rows, renaming it to "skill_name":
skill_counts <- full_df %>%
  separate_rows(skills, sep = ",") %>%    # Split skills by commas into individual rows
  rename(skill_name = skills) %>%         # Rename the column to "skill_name"
  mutate(skill_name = str_trim(skill_name)) %>%  # Remove extra spaces around skill names
  count(skill_name, sort = TRUE) %>%      # Count occurrences of each skill and sort by frequency
  rename(frequency = n)                   # Rename count column to 'frequency'

# 2. Display the top skills
head(skill_counts, 10)  # Show the top 10 skills by frequency
```

```{r}
library(ggplot2)

# Plot the top 10 skills
ggplot(skill_counts %>% head(10), aes(x = reorder(skill_name, -frequency), y = frequency)) +
  geom_bar(stat = "identity") +
  labs(title = "Top 10 Skills in Data Science Job Postings",
       x = "Skill",
       y = "Frequency") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

```{r}


# List of text columns to normalize
text_columns <- c("job_title", "job_summary", "job_location", "search_position", "company")

# Apply normalization to each text column
full_df <- full_df %>%
  mutate(across(all_of(text_columns), ~ str_trim(tolower(.))))

# Display the first few rows of the updated dataset
head(full_df)

```

##This is some basic statistics that can be used in the project
```{r Some-statistics}

library(dplyr)
library(tidyr)
library(stringr)

# Step 1: Load full_df and collect data for in-memory processing
full_df <- full_df %>%
  collect()  # If full_df is still lazy, convert it to an in-memory data frame

# Step 2: Basic summary statistics for numeric columns
numeric_summary <- full_df %>%
  summarise(across(where(is.numeric), list(mean = mean, sd = sd, min = min, max = max), na.rm = TRUE))

print("Numeric Summary:")
print(numeric_summary)

# Step 3: Counts of unique values in each character column
unique_counts <- full_df %>%
  summarise(across(where(is.character), ~n_distinct(.)))

print("Unique Counts in Character Columns:")
print(unique_counts)

# Step 4: Distribution of job titles and top companies
job_title_distribution <- full_df %>%
  count(job_title, sort = TRUE) %>%
  head(10)  # Top 10 job titles

company_distribution <- full_df %>%
  count(company, sort = TRUE) %>%
  head(10)  # Top 10 companies

print("Top 10 Job Titles by Frequency:")
print(job_title_distribution)

print("Top 10 Companies by Frequency:")
print(company_distribution)

# Step 5: Count of skills per job
skill_counts_per_job <- full_df %>%
  mutate(num_skills = str_count(skills, ",") + 1) %>%  # Count skills based on commas
  summarise(mean_skills = mean(num_skills, na.rm = TRUE), 
            median_skills = median(num_skills, na.rm = TRUE), 
            max_skills = max(num_skills, na.rm = TRUE))

print("Skill Count Per Job Statistics:")
print(skill_counts_per_job)

# Step 6: Most Common Skills
skills_long <- full_df %>%
  separate_rows(skills, sep = ",") %>%   # Split skills into individual rows
  mutate(skills = str_trim(skills)) %>%  # Trim spaces around skill names
  count(skills, sort = TRUE) %>%         # Count the frequency of each skill
  rename(skill_name = skills) %>%
  head(10)                               # Top 10 skills by frequency

print("Top 10 Most Common Skills:")
print(skills_long)

# Step 7: Overview of missing values
missing_values <- full_df %>%
  summarise(across(everything(), ~sum(is.na(.))))

print("Missing Values in Each Column:")
print(missing_values)

```
